{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce235023-5d70-45e2-b08c-b5c28b62627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumberNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
      "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.6 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.1/5.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.4/5.6 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.9/5.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pytesseract, pypdfium2, pdf2image, pdfminer.six, pdfplumber\n",
      "Successfully installed pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ac6d34-4fec-436d-ae95-4b452dbd0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc8a5ad-4cd5-4e8f-bf3a-e132678a3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a6ec51-f7f6-41b5-97fc-1310f9eb28a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "FUNCTIONAL\n",
      "IM A. SAMPLE IV\n",
      "987 Northridge Drive\n",
      "Omaha, Nebraska 68123\n",
      "(402) 543-1234\n",
      "imasample4@xxx.com\n",
      "OBJECTIVE: Position in market research or financial analysis where strong technical skills,\n",
      "mathematical/statistical background and problem solving abilities can be applied towards\n",
      "the successful achievement of business goals and objectives\n",
      "PROFESSIONAL PROFILE\n",
      " Exceptionally well organized, resourceful and highly motivated with the ability to handle\n",
      "multiple projects and produce timely, high quality work.\n",
      " Strong analytical and human relations skills; especially effective in helping customers\n",
      "and associates resolve issues and concerns.\n",
      "PROFESSIONAL SKILLS AND EXPERIENCE\n",
      "Analysis and Problem Solving\n",
      " Researched and developed a survey instrument, subsequently used to obtain information\n",
      "from customers regarding their satisfaction with products purchased.\n",
      " Compiled and analyzed statistical data to identify potential target markets for future sales\n",
      "and marketing efforts.\n",
      " Completed independent research project on the use of mathematical/statistical models as\n",
      "tools for solving various business problems.\n",
      " Conducted quality control inspections, analyzed results and developed action plans to\n",
      "address areas of concern.\n",
      "Communications and Customer Relations\n",
      " Received Customer Service Satisfaction Award for high quality of services provided to\n",
      "both vendors and customers.\n",
      " Handled customer inquiries and sales; effectively represented company to vendors and\n",
      "prospective customers, resulting in a 15% increase in sales in just six months.\n",
      " Provided orientation, training and guidance to new employees.\n",
      "EDUCATION\n",
      "Bachelor of Science, Bellevue University, Bellevue, NE (June, 20xx)\n",
      "Major: Computer Information Systems in Business Minor: Mathematics\n",
      "Graduated summa cum laude GPA: 3.98/4.00\n",
      "TECHNICAL SKILLS\n",
      " Java, PERL, ASP, PHP Scripting, Relational Databases, SQL\n",
      " Inferential Statistics, Data Analysis, Calculus & Mathematical Analysis, SPSS\n",
      "WORK EXPERIENCE\n",
      "Intern-Market Research, Mutual of Omaha, Omaha, NE (Fall Semester, 20xx)\n",
      "Sales Associate & Machinist Assistant, Precision Tool, Omaha, NE (20xx to present)\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Sample_Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470fe9c2-8786-42d9-afce-ebc973103361",
   "metadata": {},
   "source": [
    "# Setting Google Gemini API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63806e9-b099-4fbe-b693-ce7acb2ec962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.182.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google.generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google.generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google.generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google.generativeai) (4.11.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio-1.75.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.4.26)\n",
      "Collecting typing-extensions (from google.generativeai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.5/1.3 MB 109.6 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 0.5/1.3 MB 109.6 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 0.5/1.3 MB 109.6 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 0.5/1.3 MB 109.6 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 157.5 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 157.5 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 157.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 1.0/1.3 MB 204.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 1.3/1.3 MB 262.2 kB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_api_python_client-2.182.0-py3-none-any.whl (14.2 MB)\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.2 MB 699.0 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.8/14.2 MB 860.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 0.8/14.2 MB 860.9 kB/s eta 0:00:16\n",
      "   -- ------------------------------------- 1.0/14.2 MB 774.8 kB/s eta 0:00:17\n",
      "   -- ------------------------------------- 1.0/14.2 MB 774.8 kB/s eta 0:00:17\n",
      "   --- ------------------------------------ 1.3/14.2 MB 762.6 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.6/14.2 MB 749.0 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.6/14.2 MB 749.0 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 1.8/14.2 MB 745.8 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.1/14.2 MB 772.6 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/14.2 MB 772.6 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.4/14.2 MB 775.9 kB/s eta 0:00:16\n",
      "   ------- -------------------------------- 2.6/14.2 MB 778.4 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.6/14.2 MB 778.4 kB/s eta 0:00:15\n",
      "   -------- ------------------------------- 2.9/14.2 MB 783.9 kB/s eta 0:00:15\n",
      "   -------- ------------------------------- 2.9/14.2 MB 783.9 kB/s eta 0:00:15\n",
      "   -------- ------------------------------- 2.9/14.2 MB 783.9 kB/s eta 0:00:15\n",
      "   -------- ------------------------------- 3.1/14.2 MB 718.2 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 3.4/14.2 MB 737.6 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 3.9/14.2 MB 812.8 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 4.5/14.2 MB 891.8 kB/s eta 0:00:11\n",
      "   -------------- ------------------------- 5.2/14.2 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.8/14.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.3/14.2 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.1/14.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.1/14.2 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.7/14.2 MB 1.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.4/14.2 MB 1.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.2 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.3/14.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 13.4/14.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.2/14.2 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio-1.75.0-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.8/4.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.3/4.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.1/4.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.9/4.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: uritemplate, typing-extensions, rsa, protobuf, httplib2, proto-plus, grpcio, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.182.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google.generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.75.0 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 rsa-4.9.1 typing-extensions-4.15.0 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b08792d9-c1f4-4932-a915-b96502c0135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab536c61-cda9-4946-8120-518947dd0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1290ffc-faab-4a58-bcbe-4311f97a6117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0009367600083351135\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 10,\n",
      "        \"total_token_count\": 17\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6547ea5-ed4e-4974-869f-b9c77ac65d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2c9f7-22e9-4391-8972-36893b3dc2c7",
   "metadata": {},
   "source": [
    "# Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5825627-d035-4eaf-b2f9-b5699728317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
    "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to imorve his resume , alos suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following job description:\n",
    "        \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36dd4ae4-11ce-4ce3-a35a-5db3bf0659da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Evaluation: I.M. Sample IV\n",
      "\n",
      "**Role Focus:**  My expertise is in Data Science. I'll evaluate this resume for suitability to a Data Science or Data Analyst role.\n",
      "\n",
      "**Overall Assessment:** The resume presents a candidate with a strong academic background and some relevant skills, but it lacks the depth and specific examples needed to be competitive for a Data Science or Data Analyst position.  The objective is too broad, and the work experience section needs significant improvement.  The skills listed are somewhat outdated and lack modern tools prevalent in Data Science.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Strong Academic Record:** Summa cum laude graduation with a BS in Computer Information Systems and a Mathematics minor demonstrates strong academic aptitude and dedication.  The GPA is excellent.\n",
      "* **Relevant Skills Foundation:** The resume shows a basic understanding of relevant skills like SQL, statistical analysis, and programming languages (though some are outdated).\n",
      "* **Problem-Solving Skills:** The description of projects and work experience hints at problem-solving abilities, crucial for data roles.\n",
      "* **Customer Service Acumen:** The Customer Service Award and sales increase demonstrate strong customer interaction skills, valuable in any role.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Vague Objective:**  The objective statement is generic and doesn't highlight specific career goals within data science/analysis.\n",
      "* **Weak Work Experience:** The work experience section is underwhelming. While the internship is relevant, the description is insufficient. The \"Sales Associate & Machinist Assistant\" role needs contextualization to highlight transferable skills applicable to a data-related job.  No quantifiable achievements are mentioned.\n",
      "* **Outdated Technical Skills:**  While Java, Perl, and ASP were relevant years ago, they're not the primary languages used in modern Data Science.  The resume should emphasize Python, R, or SQL (which is mentioned, but needs more detail).  Mentioning cloud platforms (AWS, Azure, GCP) would be beneficial.\n",
      "* **Lack of Project Detail:** The descriptions of projects are too brief.  For example, the \"independent research project\" needs elaboration: What problem was solved? What methodology was used? What were the results?  Quantifiable results are essential.\n",
      "* **Missing Data Visualization Skills:**  No mention of data visualization tools (Tableau, Power BI, Matplotlib, Seaborn) which are critical for data roles.\n",
      "* **Absence of Portfolio:**  A portfolio showcasing projects (e.g., GitHub repository) would significantly strengthen the application.\n",
      "\n",
      "\n",
      "**Skills Candidate Already Has:**\n",
      "\n",
      "* SQL\n",
      "* Inferential Statistics\n",
      "* Data Analysis\n",
      "* Java, Perl, ASP, PHP (Outdated – needs updating)\n",
      "* SPSS\n",
      "* Customer Service\n",
      "* Problem-Solving\n",
      "* Basic Data Collection (Survey creation)\n",
      "\n",
      "\n",
      "**Skills to Improve:**\n",
      "\n",
      "* **Programming Languages:** Python (Pandas, NumPy, Scikit-learn), R\n",
      "* **Data Visualization:** Tableau, Power BI, Matplotlib, Seaborn\n",
      "* **Big Data Technologies:** Spark, Hadoop (depending on the specific role)\n",
      "* **Cloud Computing:** AWS, Azure, or GCP\n",
      "* **Machine Learning Algorithms:** Regression, Classification, Clustering\n",
      "* **Data Wrangling/Cleaning:** Techniques for handling missing data, outliers, etc.\n",
      "* **Version Control:** Git\n",
      "* **Data Storytelling:**  Communicating insights effectively through visualizations and presentations\n",
      "\n",
      "\n",
      "**Suggested Courses:**\n",
      "\n",
      "* **Python for Data Science:** Numerous online courses (Coursera, edX, DataCamp)\n",
      "* **R Programming:** Similar online courses as above\n",
      "* **Data Visualization with Tableau/Power BI:** Online courses and certifications\n",
      "* **Machine Learning:**  Coursera's Andrew Ng's course, various online courses on platforms like Udemy and edX.\n",
      "* **Big Data Technologies (if relevant):**  Cloud-specific courses on AWS, Azure, or GCP; courses on Spark/Hadoop.\n",
      "\n",
      "\n",
      "**Recommendations for Resume Improvement:**\n",
      "\n",
      "1. **Rewrite the Objective:** Focus on a specific data-related role (e.g., \"Entry-level Data Analyst position leveraging strong analytical and programming skills to contribute to data-driven decision-making\").\n",
      "2. **Expand Work Experience:** Quantify accomplishments.  For the internship, detail the projects undertaken and the impact. For the Sales Associate role, highlight transferable skills like data entry, analysis of sales figures, or problem-solving in customer interactions.\n",
      "3. **Update Technical Skills:**  Focus on modern, in-demand languages and tools. Remove outdated ones or place them lower down.\n",
      "4. **Showcase Projects:** Add a dedicated \"Projects\" section with detailed descriptions of completed projects, highlighting methodology, results, and challenges overcome.  Include links to GitHub repositories if available.\n",
      "5. **Add a Portfolio Link:**  If projects are substantial, include a link to a portfolio website or GitHub profile.\n",
      "6. **Quantify Achievements:** Use numbers to demonstrate impact (e.g., \"Increased sales by 15%,\" \"Improved data accuracy by 10%\").\n",
      "7. **Tailor to Specific Jobs:**  Customize the resume for each job application, highlighting the most relevant skills and experiences.\n",
      "\n",
      "\n",
      "By addressing these weaknesses and highlighting his strengths more effectively, I.M. Sample IV can significantly improve his chances of landing a data science or data analyst role.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb76449-c835-4aed-ab63-f3b3ce6a10ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
